{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPsraO7XFDkBTKh2SSjsuHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julia-sokol/Cheching-git2/blob/master/Deep_Learning_for_the_Life_Sciences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4d6oGbno41E",
        "outputId": "a31158cd-2225-40ef-f24d-cb8d98c3ca6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepchem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmbmfxBVpCXY",
        "outputId": "2a5a8b0e-eeb0-4a9d-ab9f-5776bbf72098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.8.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.3)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\n",
            "Collecting rdkit (from deepchem)\n",
            "  Downloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (10.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
            "Downloading deepchem-2.8.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdkit-2024.3.5-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit, deepchem\n",
            "Successfully installed deepchem-2.8.0 rdkit-2024.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Dataset: Dataset object"
      ],
      "metadata": {
        "id": "9AitQ1pvq2k1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "import numpy as np\n",
        "\n",
        "x = np.random.random((4, 5))\n",
        "y = np.random.random((4, 1))\n",
        "\n",
        "dataset = dc.data.NumpyDataset(x, y)\n",
        "\n",
        "# We can unwrap the dataset object to get at the original arrays that we stored inside:\n",
        "print(dataset.X)\n",
        "\n",
        "# Note that these arrays are the same as the original arrays x and y:\n",
        "np.array_equal(x, dataset.X)\n"
      ],
      "metadata": {
        "id": "DAOXypQUpRJY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88058018-287d-4c62-8b75-72603e23a9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.09671117 0.07083815 0.93516128 0.32838675 0.54867976]\n",
            " [0.81982269 0.36819602 0.0448289  0.06738849 0.55714923]\n",
            " [0.02359447 0.50457147 0.20094097 0.32121895 0.16067396]\n",
            " [0.11801438 0.33191974 0.10084576 0.9825433  0.71926731]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Premade Model to Predict Toxicity of Molecules"
      ],
      "metadata": {
        "id": "JzXmxx_avtTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a data"
      ],
      "metadata": {
        "id": "psnqStxmxtdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()\n",
        "\n",
        "# 1 Tasks:\n",
        "\n",
        "# In : len(tox21_tasks)\n",
        "# Out: 12\n",
        "#  Each of the 12 tasks here corresponds with a particular biological experiment. In this\n",
        "# case, each of these tasks is for an enzymatic assay which measures whether the mole‐\n",
        "# cules in the Tox21 dataset bind with the biological target in question.\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets\n",
        "\n",
        "# In : train_dataset.X.shape\n",
        "# Out: (6264, 1024)\n",
        "\n",
        "# In : np.shape(train_dataset.y)\n",
        "# Out: (6264, 12)\n",
        "np.shape(train_dataset.y)\n",
        "\n",
        "# There are 12 data points, also known as labels, for each sample. These correspond to\n",
        "# the 12 tasks we discussed earlier.\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JO375CK1v2By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking missing labels (y)"
      ],
      "metadata": {
        "id": "n7f75vW4x43Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The actual experimental dataset for Tox21 did not\n",
        "# test every molecule in every biological experiment. That means that some of these\n",
        "# labels are meaningless placeholders.\n",
        "# We can check the dataset’s w\n",
        "# field, which records its weights. Whenever we compute the loss function for a model,\n",
        "# we multiply the term associated with each sample-task pair by its w. If the corresponding label is missing, the weight is 0.\n",
        "\n",
        "train_dataset.w.shape\n",
        "# Out: (6264, 12)\n",
        "\n",
        "np.count_nonzero(train_dataset.w == 0)\n",
        "# Out: 13002\n",
        "\n",
        "# Of the 6,264 × 12 = 75,168 elements in the array of labels, only 62,166 were actually measured The other 13,002 correspond to missing measurements and should be\n",
        "# ignored. You might ask, then, why we still keep such entries around. The answer is\n",
        "# mainly for convenience; irregularly shaped arrays are much harder to reason about\n",
        "# and deal with in code than regular matrices with an associated set of weights.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_QM0nwfXyBWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining transformers"
      ],
      "metadata": {
        "id": "aqKeFEJIOhCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformers\n",
        "\n",
        "# BalancingTransformer handles imbalanced data. It adjusts the weights for individual data points in the loss function so that\n",
        "# the total weight assigned to every class is the same."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB4kVDgsOoTJ",
        "outputId": "d4d11453-a13f-4cba-c39d-9e4449825db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<deepchem.trans.transformers.BalancingTransformer at 0x7f703dc89930>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with models"
      ],
      "metadata": {
        "id": "iFjEsz00d5D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepChem’s dc.models submodule contains a variety of\n",
        "# different life science–specific models. All of these various models inherit from the\n",
        "# parent class dc.models.Model.\n",
        "\n",
        "\n",
        "# 1 Create the model\n",
        "# layer_sizes is a list of widths of fully connected hidden layers\n",
        "model = dc.models.MultitaskClassifier(n_tasks=12,\n",
        "  n_features=1024,\n",
        "  layer_sizes=[1000])\n",
        "\n",
        "# 2 Training\n",
        "# In an ideal world, you would need just one epoch, bc you would reach a\n",
        "# well-optimized model before running out of data. In practice, there usually isn’t\n",
        "# enough training data for that, so you run out of data before the model is fully trained.\n",
        "# You then need to start reusing data, making additional passes through the dataset.\n",
        "# This lets you train models with smaller amounts of data, but the more epochs you\n",
        "# use, the more likely you are to end up with an overfit model.\n",
        "\n",
        "model.fit(train_dataset, nb_epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_DeThgAd_f0",
        "outputId": "771e7dc8-65f3-42ce-97bf-45374d3c66b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49126462936401366"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the performance of the trained model"
      ],
      "metadata": {
        "id": "RMweboXTf2sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 The DeepChem class dc.metrics.Metric provides a general way to specify metrics for models.\n",
        "\n",
        "# 2  ROC AUC theory:\n",
        "#  We want to classify molecules as toxic or nontoxic, but the model\n",
        "# outputs continuous numbers, not discrete predictions. In practice,\n",
        "# you pick a threshold value and predict that a molecule is toxic\n",
        "# whenever the output is greater than the threshold. A low threshold\n",
        "# will produce many false positives (predicting a safe molecule is\n",
        "# actually toxic). A higher threshold will give fewer false positives but\n",
        "# more false negatives (incorrectly predicting that a toxic molecule is\n",
        "# safe).  If there exists any threshold value\n",
        "# for which every sample is classified correctly, the ROC AUC score\n",
        "# is 1. At the other extreme, if the model outputs completely random\n",
        "# values unrelated to the true classes, the ROC AUC score is 0.5.\n",
        "\n",
        "\n",
        "# 3 Evaluate\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
        "\n",
        "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
        "test_scores = model.evaluate(test_dataset, [metric], transformers)\n",
        "\n",
        "print(train_scores)\n",
        "print(test_scores)\n",
        "\n",
        "\n",
        "# 4 Reason about the output\n",
        "# Out\n",
        "# {'mean-roc_auc_score': 0.9659541853946179}\n",
        "# {'mean-roc_auc_score': 0.7915464001982299}\n",
        "# Notice that our score on the training set (0.96) is much better than our score on the\n",
        "# test set (0.79). This shows the model has been overfit."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s6W0-Uof6jX",
        "outputId": "2617f1c1-7473-4e46-9d12-ae1c1760e31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mean-roc_auc_score': 0.9585963273822548}\n",
            "{'mean-roc_auc_score': 0.6856379388070523}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a New Deep Learning Architecture\n",
        "## Convolutional neural network on the MNIST digit recognition dataset"
      ],
      "metadata": {
        "id": "yypcXpqviDTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1\n",
        "# dc.models.TensorGraph class, which provides a framework for building deep architectures in DeepChem.\n",
        "\n",
        "# 2\n",
        "# Where to used premade and when to use your own architecture?\n",
        "# If you have a well-debugged canned architecture for a problem, it will\n",
        "# likely make sense to use it. But if you’re working on a new dataset\n",
        "# where no such architecture has been put together, you’ll often have\n",
        "# to create a custom architecture.\n",
        "\n",
        "# 3 downloading mnist\n",
        "!mkdir MNIST_data\n",
        "!cd MNIST_data"
      ],
      "metadata": {
        "id": "_YwW3h3CiYdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code does not work. Just read through, do not run it"
      ],
      "metadata": {
        "id": "hRFejNoCrSS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow_datasets\n",
        "import tensorflow_datasets as tfds\n",
        "mnist = tfds.load(name='mnist')\n"
      ],
      "metadata": {
        "id": "rZmaXnVkkCDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+http://github.com/tensorflow/examples.git\n",
        "\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
      ],
      "metadata": {
        "id": "Qi2N7y7RmEO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "import tensorflow as tf\n",
        "import deepchem.models.tensorgraph.layers as layers\n",
        "\n",
        "# 1 Prepare the dataset\n",
        "train_dataset = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\n",
        "test_dataset = dc.data.NumpyDataset(mnist.test.images, mnist.test.labels)\n",
        "\n",
        "# 2\n",
        "# Create the model object\n",
        "# The model_dir option specifies a directory where the model’s parameters should be saved.\n",
        "model = dc.models.TensorGraph(model_dir='mnist')\n",
        "\n",
        "# 3\n",
        "# Note that since TensorGraph inherits from Model, this object is an instance of\n",
        "# dc.models.Model and supports the same fit() and evaluate() functions we saw\n",
        "# previously.\n",
        "# In : isinstance(model, dc.models.Model)\n",
        "# Out: True\n",
        "\n",
        "# 4\n",
        "# Create the input and output layers in the computational graph, which acts as a placeholder for the input data.\n",
        "# None stands for 'any dimension'\n",
        "feature = layers.Feature(shape=(None, 784))\n",
        "label = layers.Label(shape=(None, 10))\n",
        "\n",
        "# 5\n",
        "# In order to apply convolutional layers to our input, we need to convert our flat feature\n",
        "# vectors into matrices of shape (28, 28). To do this, we will use a Reshape layer:\n",
        "make_image = layers.Reshape(shape=(None, 28, 28), in_layers=feature)\n",
        "\n",
        "# 6\n",
        "# Create convolutional layers:\n",
        "# the 3rd parameter indicates the data which is input to the layer\n",
        "conv2d_1 = layers.Conv2D(num_outputs=32, activation_fn=tf.nn.relu,\n",
        " in_layers=make_image)\n",
        "conv2d_2 = layers.Conv2D(num_outputs=64, activation_fn=tf.nn.relu,\n",
        " in_layers=conv2d_1)\n",
        "\n",
        "# 7\n",
        "# Create a fully-connected layer called Dense:\n",
        "\n",
        "# 1) flatten the output from convolutional level:\n",
        "# the output of Conv2D layers is 2D, so we will first need to apply a Flat\n",
        "# ten layer to flatten our input to one dimension (more precisely, the Conv2D layer pro‐\n",
        "# duces a 2D output for each sample, so its output has three dimensions; the Flatten\n",
        "# layer collapses this to a single dimension per sample, or two dimensions in total)\n",
        "flatten = layers.Flatten(in_layers=conv2d_2)\n",
        "dense1 = layers.Dense(out_channels=1024, activation_fn=tf.nn.relu,\n",
        " in_layers=flatten)\n",
        "\n",
        "# 2) create the layer\n",
        "# The out_channels argument in a Dense layer specifies the width of the layer.\n",
        "dense2 = layers.Dense(out_channels=10, activation_fn=None, in_layers=dense1)\n",
        "\n",
        "#8\n",
        "#  We now want to hook this output up to a loss function, so we can train the output to accurately predict classes. We will use the\n",
        "# SoftMaxCrossEntropy loss to perform this form of training:\n",
        "\n",
        "# description is below\n",
        "smce = layers.SoftMaxCrossEntropy(in_layers=[label, dense2])\n",
        "loss = layers.ReduceMean(in_layers=smce)\n",
        "model.set_loss(loss)\n",
        "\n",
        "# Note that the SoftMaxCrossEntropy layer accepts both the labels and the output of\n",
        "# the last Dense layer as inputs. It computes the value of the loss function for every\n",
        "# sample, so we then need to average over all samples to obtain the final loss. This is\n",
        "# done with the ReduceMean layer, which we set as our model’s loss function by calling\n",
        "# model.set_loss().\n",
        "\n",
        "# 9\n",
        "# If we want to obtain per-class out‐put probabilities. We’ll add this output to model with model.add_output():\n",
        "output = layers.SoftMax(in_layers=dense2)\n",
        "model.add_output(output)\n",
        "\n",
        "# 10 train the model\n",
        "model.fit(train_dataset, nb_epoch=10)\n",
        "\n",
        "# 11 evaluate accuracy\n",
        "metric = dc.metrics.Metric(dc.metrics.accuracy_score)\n",
        "\n",
        "train_scores = model.evaluate(train_dataset, [metric])\n",
        "test_scores = model.evaluate(test_dataset, [metric])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "WsnJd_ZwreVx",
        "outputId": "c9ab8e23-bc9e-4d4c-96ba-9ffcd7f6152f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deepchem.models.tensorgraph'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-cb45d669dfc1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdeepchem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1 Prepare the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepchem.models.tensorgraph'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning for Molecules"
      ],
      "metadata": {
        "id": "u66OaDMv6PSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: substitute the random search for molecules with desired properties with testing molecules that ml models predicted\n",
        "to have the desired properties.\n",
        "\n",
        "1. Transform chemical formulas into vectors of numbers that\n",
        "can then be passed to learning algorithms -- molecule featurizauion.\n",
        "\n",
        "2. Select learning algorithm."
      ],
      "metadata": {
        "id": "HUvVl2Kg6zyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important molecular topics to review:\n",
        "\n",
        "1. Types of molecular bonds.\n",
        "2. Molecular conformations.\n",
        "3. Chilarity: molecules have identical molecular graphs, so ML models that depend only on molecular graphs cannot properly distinguish between them.\n",
        "\n",
        "Example:\n",
        " The R form of thalidomide is an effective sedative, while\n",
        "the S form is teratogenic and has been shown to cause severe birth defects. These dif‐\n",
        "ficulties are further compounded by the fact that thalidomide interconverts, or race‐\n",
        "mizes, between the two different forms in the body."
      ],
      "metadata": {
        "id": "X3HhKRKVdJDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Featurization\n",
        "\n",
        "There are some deep learning models that directly accept SMILES strings as\n",
        "their inputs, attempting to learn to identify meaningful features in the text represen‐\n",
        "tation. But much more often, we first convert the string into a different representa‐\n",
        "tion (or featurize it) better suited to the problem at hand.\n",
        "\n",
        "1. Extended-Connectivity Fingerprints  (ECFPs)\n",
        "Vectors of 1s and 0s that represent the presence or absence of specific features in a molecule.\n",
        "They take molecules of\n",
        "arbitrary size and convert them into fixed-length vectors.\n",
        "\n",
        "The algorithm\n",
        "begins by considering every atom independently and looking at a few properties of\n",
        "the atom: its element, the number of covalent bonds it forms, etc. Each unique com‐\n",
        "bination of these properties is a feature, and the corresponding elements of the vector\n",
        "are set to 1 to indicate their presence. The algorithm then works outward, combining\n",
        "each atom with all the ones it is bonded to. This defines a new set of larger features,\n",
        "and the corresponding elements of the vector are set. The most common variant of\n",
        "this technique is the ECFP4 algorithm, which allows for sub-fragments to have a\n",
        "radius of two bonds around a central atom.\n",
        "\n",
        "2. Molecular Descriptors\n",
        "\n",
        "These usually correspond to various computed quantities\n",
        "that describe the molecule’s structure.\n",
        "This featurization is obviously more useful for some problems than others. It will\n",
        "tend to work best for predicting things that depend on relatively generic properties of\n",
        "the molecules. It is unlikely to work for predicting properties that depend on the\n",
        "detailed arrangement of atoms.\n",
        "\n",
        "3. Graph Convolutions\n",
        "\n",
        "Graph convolutional networks take the same idea as in image recognition and apply it to graphs. Just as a reg‐\n",
        "ular CNN begins with a vector of numbers for each pixel, a graph convolutional network begins with a vector of numbers for each node and/or edge. When the graph\n",
        "represents a molecule, those numbers could be high-level chemical properties of each\n",
        "atom, such as its element, charge, and hybridization state. Just as a regular convolu‐\n",
        "tional layer computes a new vector for each pixel based on a local region of its input,\n",
        "a graph convolutional layer computes a new vector for each node and/or edge. The\n",
        "output is computed by applying a learned convolutional kernel to each local region of\n",
        "the graph, where “local” is now defined in terms of edges between nodes. For exam‐\n",
        "ple, it might compute an output vector for each atom based on the input vector for\n",
        "that same atom and any other atoms it is directly bonded to.\n",
        "\n",
        "There are many different variants of these models all available through DeepChem.\n",
        "\n",
        "limitation: the calculation is based solely on the molecular graph.\n",
        "They receive no information about the molecule’s conformation, so they cannot hope\n",
        "to predict anything that is conformation-dependent. This makes them most suitable\n",
        "for small, mostly rigid molecules."
      ],
      "metadata": {
        "id": "zAnsi7prftnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1.\n",
        "smiles = ['C1CCCCC1', 'O1CCOCC1'] # cyclohexane and dioxane\n",
        "mols = [Chem.MolFromSmiles(smile) for smile in smiles]\n",
        "feat = dc.feat.CircularFingerprint(size=1024)\n",
        "arr = feat.featurize(mols)\n",
        "# arr is a 2-by-1024 array containing the fingerprints for\n",
        "# the two molecules\n",
        "\n",
        "2.\n",
        "feat = dc.feat.RDKitDescriptors()\n",
        "arr = feat.featurize(mols)\n",
        "# arr is a 2-by-111 array containing properties of the\n",
        "# two molecules`\n",
        "\n"
      ],
      "metadata": {
        "id": "ZGYnE7lrmEMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Model to Predict Solubility"
      ],
      "metadata": {
        "id": "9FZcOiVMnpTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepchem\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b9c2a-a46d-45ef-aa16-f44ec6aa7bee",
        "id": "uPenIn-Ko4uv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.3)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2024.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (10.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import deepchem as dc\n",
        "import numpy as np\n",
        "\n",
        "#1 Load the data\n",
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets\n",
        "\n",
        "# Notice that when downloading the data we specify the option featurizer='GraphConv'.\n",
        "#  We are going to use a\n",
        "# graph convolutional model, and this tells MoleculeNet to transform the SMILES\n",
        "# string for each molecule into the format required by the model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nO-kmXun8ff",
        "outputId": "66fb1e8d-59fb-4ccc-8b16-b3fccc8c4f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.10.0 # Or an earlier version where 'legacy' optimizers are supported\n",
        "!pip install keras==2.10.0 # Or a corresponding Keras version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TCVtFdKGtlr1",
        "outputId": "b483403e-f53a-4838-9d22-6902e303956c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.10.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.11.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-aiplatform 1.70.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.26.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.25.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "google",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "d729edd5efe94bb8a8adde430b10f198"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from deepchem.models import GraphConvModel\n",
        "\n",
        "model = dc.models.GraphConvModel(1, mode='regression', dropout=0.2, batch_normalize=False)\n",
        "model.fit(train_dataset, nb_epoch=100)\n",
        "\n",
        "# We specify that this is a regression model, meaning that the\n",
        "# labels are continuous numbers and the model should try to reproduce them as accu‐\n",
        "# rately as possible"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yakQAyS7pUiU",
        "outputId": "f650617a-15a7-4a9e-aa1d-4095b9f778d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(333,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(333, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(1008,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(1008, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(843,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(843, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(108, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(333,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(333, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(1008,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(1008, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(843,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(843, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(108, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(333,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(333, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(1008,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(1008, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(843,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(843, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(108,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(108, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06357300758361817"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print(model.evaluate(train_dataset, [metric], transformers))\n",
        "print(model.evaluate(test_dataset, [metric], transformers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BmNuxPsp90P",
        "outputId": "66eeb993-e7c2-4f18-ebe2-53d6efba7baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pearson_r2_score': 0.9463621001498629}\n",
            "{'pearson_r2_score': 0.7194975637919466}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the model to make a prediction for other molecules"
      ],
      "metadata": {
        "id": "RcMPPx4evpUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Create a list of strings-smiles\n",
        "smiles = ['COC(C)(C)CCCC(C)CC=CC(C)=CC(=O)OC(C)C',\n",
        " 'CCOC(=O)CC',\n",
        " 'CSc1nc(NC(C)C)nc(NC(C)C)n1',\n",
        " 'CC(C#C)N(C)C(=O)Nc1ccc(Cl)cc1',\n",
        " 'Cc1cc2ccccc2cc1C']\n",
        "\n",
        "from rdkit import Chem\n",
        "# 2) This function takes a SMILES string as input and returns a molecule object that\n",
        "# represents the chemical structure.`\n",
        "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
        "\n",
        "# 3) #  As we are going to use a\n",
        "# graph convolutional model, this featurizer transforms the SMILES\n",
        "# string for each molecule into the format required by the model.\n",
        "featurizer = dc.feat.ConvMolFeaturizer()\n",
        "x = featurizer.featurize(mols)\n",
        "\n",
        "# 4) run the prediction\n",
        "predicted_solubility = model.predict_on_batch(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "LKmBm0kSvmCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MoleculeNet"
      ],
      "metadata": {
        "id": "1gv7oCVpy3qP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At http://moleculenet.ai you\n",
        "can view data on how well a collection of standard models perform on each of the\n",
        "datasets, giving insight into how your own method compares to established techni‐\n",
        "ques."
      ],
      "metadata": {
        "id": "uu9nXKioy9Yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SMARTS Strings"
      ],
      "metadata": {
        "id": "Mo14H-MwzLX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used where we\n",
        "want to determine whether atoms in a molecule match a particular pattern"
      ],
      "metadata": {
        "id": "o-io3GAE0ZoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem.Draw import MolsToGridImage\n",
        "\n",
        "# 1) write a list of smiles\n",
        "smiles_list = [\"CCCCC\",\"CCOCC\",\"CCNCC\",\"CCSCC\"]\n",
        "\n",
        "# 2) convert smile's strings into molecule objects\n",
        "mol_list = [Chem.MolFromSmiles(x) for x in smiles_list]"
      ],
      "metadata": {
        "id": "xDyVOLkE0lfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) define the pattern you want to match\n",
        "query = Chem.MolFromSmarts(\"CCC\")\n",
        "# query = Chem.MolFromSmarts(\"C*C\")\n",
        "# query = Chem.MolFromSmarts(\"C[C,N,O]C\")\n",
        "# see more in Daylight Theory Manual\n",
        "\n",
        "# 4) The method used in list comprehension returns the indices of the molecule’s\n",
        "#  atoms that match a substructure query.\n",
        "match_list = [mol.GetSubstructMatch(query) for mol in\n",
        "mol_list]\n",
        "\n",
        "# 5) visualize molecules\n",
        "MolsToGridImage(mols=mol_list, molsPerRow=4,\n",
        "                highlightAtomLists=match_list)\n",
        "\n",
        "#  Note also that there are multiple ways that the SMARTS pattern\n",
        "# could match the first molecule in this figure—it could match three adjacent carbon\n",
        "# atoms by starting at the first, second, or third carbon atom. There are additional\n",
        "# functions in RDKit that will return all possible SMARTS matches, but we won’t cover\n",
        "# those now.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "eTfXfZb1012D",
        "outputId": "a1984590-a67c-4d13-a583-392cf75092f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAAADICAIAAACf7RJNAAAABmJLR0QA/wD/AP+gvaeTAAAY40lEQVR4nO3de1CU973H8R8oRPCGSoLxbogoNWrIBRMNWgzWGGmTmcQ5M+eETNo/6Jmk2ab/lF7SwY6dkXZqD21qM6RJemhu1OlJjsSUeACvk6Sxi0Ci4aLiDQwWRKNcZGH3e/541nULgrj89nme3X2/xn+yPD7Pz2/YfT77/G5RIqIAAACgT7TVDQAAAAg3BCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwA0KO6ujo7Ozs7O7umpsbqtlivpqbGqEZ1dbXVbQEsECUiVrcBAEKby+V65plnSkpKjE/UuLi4H/7whz/60Y/GjRtnddMs4HK5Xn755RdffLGzs9N45bHHHispKYnMaiBi8QQLAEbl3XffTU1Nfeedd0QkKSlp6dKlPT09P//5zxcvXvzuu+9a3TqzGdV44YUXOjs7ly5dmpSUpJTasWNHZFYDkYyABQABqq+vX79+/RNPPNHU1LRo0aJt27a1trbW1tbu3r176dKlTU1NTzzxRGZmZm1trdUtNcOAapSVldXW1ra2tr7yyisRWA1ACQDgJp0/f97hcIwdO1YpNXXq1MLCwr6+Pv8D3G53cXHxbbfdppSKjo7Oyck5d+6cVa0NNqoBDEbAAoCb0NfXV1RUlJiYqJQaO3Zsbm7uP//5z6EOvnDhQl5eXmxsrFIqISGhoKCgt7fXzNYG2+BqtLW1DXVwR0dHeFcD8EfAAoCRqqiouOuuu4zH/w8//PBnn302kr/V0NCwYcMG42+lpKTs3Lkz2O00B9UAhkHAAoAba2xs3LhxoxEL7rzzzu3bt9/sGcrLy7/2ta8ZZ8jKyjp8+HAw2mkOqgHcEAELkaiiomLlypUrV648cOCA1W2x3oEDB4xqVFRUWN0WO+rs7MzPz7/llluUUuPHj8/Pz79y5Upgp3K5XIWFhZMnT1ZKxcTEOByOixcv6m1tsF2+fJlqmOz9999PS0tLS0vbtWuX1W2x3q5du4xqvP/++1a35QYIWIgsnZ2dvu4JPtb9o4MhMzMzYqsxmDE021howBia/eWXX47+tO3t7Q6HY8yYMUqpadOmFRYW9vf3j/60wUY1zNfR0ZGVleV7e95wzF94M8bwxcTE+AqyYsUKO1eDgIVI4Xa7X3vttenTpxvvzPnz569evTo6OlopNX369Ndee83tdlvdRvP4VyM6Onr16tXz5883KhOB1biuTz/99IEHHjBqkp6e/sknn+g9/6FDh1atWmWcPy0tbd++fXrPrxfVMJn/vEulVHJy8rp164aZpxneBsxCzcjI8PUv27kaBCxEhIMHDz744IPGG/L+++//61//arxeVVWVkZFhvH7PPffs37/f2naaY0A1Pv74Y+P10tLSCKzGYM3NzTk5OVFRUUqpmTNnFhcXezyeYFzI4/GUlJTMmTNHKRUdPebZZztOnQrGdUbl1Cl59tmjxleROXPmlJSUBKkaIlJaWjpv3jzjNzA7O7upqSlIF7I5Yx0130NlX89gXV3dI488Yry+aNGiv/3tb9a20xwDqlFTU2O8vmfPHptXw+4Ba/PmzUlJSUlJSZs3b7a6LdajGgEYyc1ywMf6iRMnrGipGajG8Lq6ugoKCiZMmKCUio+Pz8vLu3z5crAv2t3dvWnTpszM/1ZK4uIkL08uXQr2NUekq0sKCmTCBFFK1qz5z02bNnV3dwf7ot3d3QUFBRMnTlRKxcXF5eXlXbJJOUxx+vTpnJwc4903e/bs4uLiwceUlpbecccdvnfosWPHzG+nOUK9GvYNWA0NDSkpKcpPSkpKQ0OD1e2yBtUIwE19UvvfWY2DTbizmsmohv8/cITVMC1nWM7aZNncLDk5EhUlSsnMmVJcLEF7TjQipaUyb54oJUpJdraYHLNNe4hoH8aASGO7xvj4+Pz8/J6enqEO7u3tLSwsnDRpkro6kPSrr74ys7XB5l8NYy5FKFbDjgHLf5ZKVFRUVlZWdna28U6LwCHJVCMwgfU1hOvHOtUYnn16ig8elAcf9Maa+++Xq523pqqqkowMbxvuuUcs7Cgeqi87zHg8nu3btxs9xVFRURs3bjw1sq7is2fP5ubmGr23t99+e1FRURgMnQynatgrYA2epXLy5EnjR83NzZE204RqBGb0o2WDPZ7XTIcOHfJFB6oxWFtbm93eSh6PFBfL9OmilERFSU6O6JirNyJtbeJwyJgxopRMmyaFhWJ1McTj8RQXFxuzMaKionRNXbSPf/zjHytWrDDeX/fdd99HH310s2dwOp0rV640znDvvfeG9NIzBw8eDKdq2Chg/f3vf1++fPnwn+ORM9OEagRA43xvI92G9Me69mpon59vLWMRJv9uBVs9DO7slPx8GTdOlJLx4yU/X4buIdHA5ZLCQpk0SZSSmBhxOMROxbi5DqNQ0dLS4nviMmPGjNE8cTGe+sydO9f31Mf3bTxUhGU1bBGwzpw54+uJmDVr1g17IkpLS31TysNvpgnVCECQVizUuMKkmajGDZWXl6emphrvmqysrCNHjljdous7elQ2bvT21t15p9z8eukjUl4uqaneq2RliV2LIUePHh3l8vE2YYwZMoaHxsbGOhwOLQP5u7q68vPz4+LifKO4TJiUMHphXA2LA1bAY2nDcqYJ1QhMsPfcaGhoyM7ONs6/YMGC/7P31mkf7ty5YMECX+DWPhNi9HukWKu+vv7RRx812r9w4cIPPvjA6hbdWGWlLFniDUBr1khtrbYz19fLo496z7xwoYRCMaSysnLJkiXG/8E1a9bUaiyHKQZ8JT5+/Lje89/sV3RrBfsBgbXVsDJglZaWGg/xVKBzdvwH4c6YMcPmv0nDoxoBMHPX2IqKCuNjvSEjQ9askZHta2uq+np59NE/ZmSYU40Advm1lrEMdGxsrFJqypQpBQUFvb29VjdqpPr6pKhIbr1VlJKxYyU3VwasX93WJsePS3Pzdf7upUty/Li0tf3Lix0dkpcnsbGilEyZIgUFEjrFkL6+vqKioltvvVWF1OLmX3zxxbp164x3TWpq6ocffhi8a+3Zs2fZsmXGtbZseaqrqzp41wpMV1f1Cy88ZbRw2bJle/bsCd619u7de/fddxvXWr16dXW1SdWwJmBVVVU99NBDxr929HN2Qn2mCdUIwIULF3w3y4SEBHNuli6X652XX5bERO9dzuGQjo5gX3REOjrE4ZCxY0Upd2Ji8csvu1yuYF/TuMklJib6bnJtA+7htuF/PzbGkIXE/Xgwv//PMmWKFBaKb/3q554TpSQ29jodfH/6kyglzz3n/U+3W4qLvVktOlpycgZmtVDR0dHhcDiMxc1tnpjPnz/vGxBprDxuwlwKY+jkrFkzqqoWOJ3RJ07kuFytwb7oSPT1nT992lFVNWbHjuSkpCQzq+E/kLS1NejVMDtg+c/ZSUxM1FXZEJ1pQjUCMGDPhJycnHPnzpnagvPnh7zLmc+4W95227W7pbnVMO4cdt7Bo7Ky0n8Z6JDrURqsvl7Wrx/Yr2cELKUkI2PgAlr+AauyUpYu9R6Zmamzt9Eq9fX169evt22frzEgMiEhwRgQaf73kJ6eC2fO/KCqKsbpVNXVCa2tWz2eoH/7GorH42pt3VpdneB0qqqqmDNnftDTc8HMBhjfzI2BpBMmTAj2QFLzAtbgOTvalwILoZkmVCMw/nsmfP3rX/ftmWCBujp55BHvnWrRIrFkl4bdu21ytxywg0dZWZlVLfHnPyZ6zpw5110GOnS9954kJ3vXU7h82RuwkpJEKXn99X850hewLl+WadNEKUlOlvfes6jdwVFaWpqcnOwbiPnFF19Y3SIRkfLy8sWLF/tapX146MhdudJ4/PhGp1M5nerzzxd0dFgwdPKrr8qPHFlstKGxMau727JqNDY2+g+rDd5AUpMClpm//ceOHbP5pyrVCMBI9kywQGmp9y5nLHdt2i4Np09LTo73urNniz2qYZ89K8Ly28VgV67Ili3y6qsiV59gbd0q48ZJYqK0t187zP8J1quvypYtErKzP4djwrfWkRswM8Ymc0EGRZzPzbluT0/D0aPZvnh38eL75lx3eAPi7+ef669G0AOWVc9v7dkvQDUCcFM7SFhg8ApCQf1YN3l9pJtk+Z4V4d0/PgwjYG3fLj/9qSgl3/nOtR8NGIMV3oI07mLk/DuhjOGhtlrNxONxtbUV1dQkGp10J0/m9vUFscuyv/9Cc3NeVdUtRgfll18WeDw2qobL5fINJA1GB24QA5blIxBtNbKVagQg4D0TLHD2rOTmSnS0KCW33y5FRaJ9lwaPR7ZvlzlzvCt8b9wodq2GVXtWRMgMj+vyBayuLpk7V6KiZPdu748iKmAZ9M4cGiFLhlEHxjfM3OlUNTVTz50r9Hi0x1B3e3txbW2S06lsNcR+sOBNQQhKwLLVHFrL52ZTjcCMfgcJCzidsnKlt+fu3ntF4y4NBw/KihXeM993n4RCNUzes2LXrl2+1W7eeuutsF+jZABfwBKRv/xFlJLFi70rL0RgwBIRj8fz1ltvzZo1y/h6tmvXrqBezqqFAEajp+eLxsZ1Rs/d4cOpX32lbdmIS5f2HjmyzDhzQ8NqGy4SMVgwFtHQH7DsuQqcVasLUo0AaNwzwQLGc6a5c689Zxpml4b6etm3T/btk/r6IY9pabn2bGzGjKA8GwsaM/es6O/vX758eaStsuvjH7BEZO1aUUq2bBGJ1IBlMFZvTk9PD97k1tBa2HOwixdLP//8DiMMHT2afeXKMAufunt7T3R1OV2u5qGeePX2njlxIsfpjHI61WefzWpvLxYJpWroXQZWZ8Cy/z4GA/bHCOrocqoRgCDtmWCBri7Jz5e4OFFK4uMlP1/8d2kwBifPnOl9ImX8mTlTfvnLf1ntsbdXCgtl4kTvAkcOh4RmNUzbsyKUgrhuAwJWY6OMGyfx8XL6dEQHLEOQfjHssBmLFh5P77lzhdXVE51OVVUVe/q0o7//0oADWlp+VlMzzchhTqeqrp7c1PQffX3XemPc7q6WlvxDh8Y5nerQofiWlny3OySrofE2pCdghdCcHRN2eKUagQn2DhIWOHFCnnzSm5/S070vdndLZqYoJZMny3e/Ky+9JC+9JLm53iC1Zs21KJae7v27Tz4pN7+yv92E+hd9mxsQsES8o91zcghY+tlnO2GNXK6Wkydznc5op1PV1s5oaysS8QbTpqanjNh04sTTLS35p09/r64uvbp6ssdjfCH0dHRs/+yzuU6ncjqjjh/f2Nsb8tXQ0pEy2oAVonN2/GeaTJs2LcJX+AxSNUbOzB0kLLB3r9x9t/zxj97//N73RClJS5MBA2BbWuSuu0QpcTi8r7zyiqSmSnhVIxSHqoSEwQGru1vuuEOiory/cQQsXUweXGiyzs6P6+rSrw6fyhTxdHcfdjpVdfWknp5/GcnQ32/sY+FpaMg0jq+rS+/sDKuZJaMcCjyqgBXqc3aqqqoyMjJ0zTShGgGwZAcJC/T3ewdONTdLTIzExsp1n8/V1cnYsRIbK2fPioi43RKO1QihyVYhZHDAEpHSUm/3MgFLC6umx5rOeCI1p6XlZyLS3l7sdKrGxm8MdXRLy4u1tbf7P/EKJ6OZzB5gwPLfV3jmzJkh/bS/tLR03rx5vp6pUe6yTDVGKNgLkNjU738vSsnjjw95wIYNopT84Q8mtskaNl8uKORcN2CJyLe+5e1nJmCNhuULvJnP7b7sdneJSEdHidOpDh9OGWpgu9vd5XZfNrd1ZgtsOcabDljd3d0FBQXG+K+4uLjwmLNjzDSZMGGCUbu8vLzLl0f060I1AmPCEro29cwzopT86ldDHrBliygl3/62iW2ykj0XvA5FQwWsU6dk/HgC1qjYZ4sCS/T2nqqqGms8xBrQSxhpbnZDkZsLWAOGITc1NY2iqbbjPwh3JA+iqEZgysrKbLtCRNAZm/S++eaQB/z5z6KUbNhgYpus98EHHyxcuND4rbDJPoYh5+23JTdXnM7r/OiNNyQ3V95+2/Q2hQXf59WSJUsqKyutbo41Wlt/Ywx+dzpVXd3ytraiAdMMI4r/6kvDf16NNGAdOnRo1apVxhnT0tL27duno5129Omnnz7wwAPGvzQ9Pf2TTz4ZfAzVGA23252VlbV161aXy7JN3S2TlSVKSUnJkAe8844oJWvXmtgmW3C5XFu3bs3KygrTQS0IVR6PJzs7e9u2bcFbSSskdHVVnTr1bE3N1KvLNEw8f/4dqxtlmb6+vm3btmVnZw//3OHGAau9vd3aKWbmGzwI1zcFt7m5mWowJDlwxqoNRUVDHrBtmyglGzea2CaEg3XrZPz466/w/9FHMn68rFtnepsQdjye3gsXdjQ2fsPYyrC7u8bqFtlatBpaX1/fb3/72+Tk5N/97nfR0dEOh+P48ePf//73jXgRxqKjo59++uljx47l5+fHxMS88cYb8+fPX7t27Te/+c3Zs2dTjeTk5E2bNvX29lrdtBC0aJFSSh05MuQBhw8rpdTVBWCBEeruVl1dyu2+zo/cbtXVpbq7TW8Twk5UVGxCwrcWLPgwIeFxkb729tetbpG9DRO+ysvLjWM2bNjQ0NBgWuizlYaGhpSUFP+KpaSkRHI1NmzYYNShvLzc6uaEoMpKUUrmzbv+djd9fd7l3ffuNb1lCG0ZGaKUXHdxlf37RSnJyDC9TQhf7e2vO53q2LHHrG6IrQ33BCsrK+v5558vKyvbuXPngJAROYw4tXnz5qSkpKSkpM2bNw+OXJEjJSVl586dZWVlzz//fFZWltXNCUGZmSo1VZ08qQoLr/PTX/9atbSoJUvU1RF+AGBDV640KKXGjJlqdUNsLUpErG4DEEk++khlZiq3W/3kJ+qFF9S0aUop1d6ufvMbVVCgYmLU/v1q+XKrW4kQs2qVOnBA7d+vrq4WfM2BA2rVKpWRofbvt6JlCHGdnQcuXnxv6tR/j4+/TymllFy8+N6JE095PD3Jyf+bkPCYxe2zsbFWNwCIMCtXqh071NNPq1/8Qm3ZombMUEqps2eV261uu029+SbpCoB9XLz43rlz/3Xu3H9FR4+PiZne39/mdl9SSt1663dJV8MjYAGmW79eHTum3nhD7d6tvvxSRUWp++9XDz+scnLUxIlWNw4h7Mc/VlMHddp0dFjRFISLWbN+nZDw+IUL/9Pdfai/vyM+Pu2WW+6cMuXfJk1aa3XT7I4uQgAIeUYXYWysih40sNbjUS4XXYSA2YYb5A4ACCEVFaqnZ+CfigqrmwVEJAIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaMY6WAAQ8pYtUyJq8uTr/GjyZPXQQ2rZMtPbBEQ21sECAADQjC5CAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmhGwAAAANCNgAQAAaEbAAgAA0IyABQAAoBkBCwAAQDMCFgAAgGYELAAAAM0IWAAAAJoRsAAAADQjYAEAAGhGwAIAANCMgAUAAKAZAQsAAEAzAhYAAIBmBCwAAADNCFgAAACaEbAAAAA0I2ABAABoRsACAADQjIAFAACgGQELAABAMwIWAACAZgQsAAAAzQhYAAAAmv0/hOhAJwBW7gMAAAB4elRYdHJka2l0UEtMIHJka2l0IDIwMjQuMDMuNQAAeJx7v2/tPQYgEABiRgYIYAViFiBuYGRjSACJM0NoJibsNCMzN1AvIxMDEzMDMwuDE8gMcTckAxlYH7qpHZg1c+Y+EOeh27L9aWnP7GCSSOL2MHGgegeYuBgAK5cabGSd9uAAAADBelRYdE1PTCByZGtpdCAyMDI0LjAzLjUAAHicjVBJDoMwDLznFfMBImdryREIqqqKILW0f+id/6uO2hA4FGHHkpfxyBOBZPdwe89YTAchANp53nu8DBGJASlB21+uEd3UtLnTjc84PeBgeYN9i2ymccgdhQ6Vls7XdD6hIpmIiVck/ZKM1AmppPaeTM1z6/4ADQOX7h6jZeARQse4Qyf2MWzEfeW2YwxFbnJdNHEBUy5XHLbcpzjcmn3Nler86ZyLDz8PV6DPOFz9AAAATXpUWHRTTUlMRVMgcmRraXQgMjAyNC4wMy41AAB4nHN2BgKFGg1dIz1TSwsDCx1dAz1jHWtdQz0jS0sDEx0DPRNTHWsDqDCqKIoWzRoAT4kPWcLLl9YAAAB9elRYdHJka2l0UEtMMSByZGtpdCAyMDI0LjAzLjUAAHice79v7T0GIBAAYkYGCGAFYhYgbmBkY0gAiTNDaCYmDgYFEA3jwqS5gVoZmRiYmBmYWRicQEaIuyGZx8D60E3twKyZM/eBOA/dlu1PS3tmB5NEEreHiQPVO8DExQAJ0xosi/esNQAAAMJ6VFh0TU9MMSByZGtpdCAyMDI0LjAzLjUAAHicjVBJDsIwDLznFfOBRs4GzbFtKoRQEwkKf+DO/4UjCGkPVLVjyct45IlAtmu4PF/4mQ5CALTxvPd4GCISE3KCfjydI4a560tnSPc43+BgeYN9jezmNJWOwoBGS+dbOh7QkMzExCuSvklB6oxUUntPpuW5dX+ABql2txgtM+4hdIzbdeIYw0rcR26fYqhys+uqiQuYernisPU+xeGW7EuuXJdP51y8AUqXV6wv0cyKAAAAUHpUWHRTTUlMRVMxIHJka2l0IDIwMjQuMDMuNQAAeJxzdvZ3dlao0dA10jO1tDCw0NE10DPWsdY11DOytDQw0THQMzHVsTaACqOKomjRrAEAUvUPZWfs0egAAAB8elRYdHJka2l0UEtMMiByZGtpdCAyMDI0LjAzLjUAAHice79v7T0GIBAAYkYGCGAFYhYgbmBkY0gAiTNDaCYmdgjNCOPD5LmBehmZGJiYGZhZGJxAZoi7IRnIwPrQTe3ArJkz94E4D92W7U9Le2YHk0QSt4eJA9U7wMTFACueGmwl8bLRAAAAwnpUWHRNT0wyIHJka2l0IDIwMjQuMDMuNQAAeJyNUEkOwjAMvOcV84FGzgbNsWkqhFBTCQp/4M7/hSMIaQ9UtWPJy3jkiUC2a7w8X/iZjkIAtPG893gYIhIjcoIwnM4J/dyF0umne5pvcLC8wb5GdvM0lo5Cj0ZL51s6HtCQzMTEK5K+SUHqjFRSe0+m5bl1f4AGqXa3GC0z7iF0jNt14pDiStxHbphSrHKz66qJC5h6ueKw9T7F4ZbsS65cl0/nXLwBSaFXqy8TWk0AAABQelRYdFNNSUxFUzIgcmRraXQgMjAyNC4wMy41AAB4nHN29nN2VqjR0DXSM7W0MLDQ0TXQM9ax1jXUM7K0NDDRMdAzMdWxNoAKo4qiaNGsAQBSrA9k/HC86gAAAH16VFh0cmRraXRQS0wzIHJka2l0IDIwMjQuMDMuNQAAeJx7v2/tPQYgEABiRgYIYAViFiBuYGRjSACJM0NoJiYBBgUQDePCpLmBWhmZGJiYGZhZGJxARoi7IZnHwPrQTe3ArJkz94E4D92W7U9Le2YHk0QSt4eJA9U7wMTFAA17GjRCcWrSAAAAwnpUWHRNT0wzIHJka2l0IDIwMjQuMDMuNQAAeJyNUEkOgzAMvOcV8wEiZ2vJEQiqqoogFdo/9M7/VUdtGjgUYceSl/HIE4Fk93B7LfiZDkIAtPO893gaIhIDUoK2v1wjurlpc6cbH3Ge4GB5g32LbOZxyB2FDpWWztd0PqEimYiJVyR9k4zUCamk9p5MzXPr/gANptLdY7TMeITQMe7QiX0MG3Efue0YQ5GbXBdNXMCUyxWHLfcpDrdmX3OlOn865+INTm9XsNr/36gAAABQelRYdFNNSUxFUzMgcmRraXQgMjAyNC4wMy41AAB4nHN2DnZ2VqjR0DXSM7W0MLDQ0TXQM9ax1jXUM7K0NDDRMdAzMdWxNoAKo4qiaNGsAQBUGQ9pWzi/OQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Biophysical Machine Learning"
      ],
      "metadata": {
        "id": "2kO7FXxG5CKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use-case for data science:\n",
        "\n",
        "1.\n",
        "We will explore in depth the problem of predicting how\n",
        "small drug-like molecules bind to a protein of interest in the human body.\n",
        "\n",
        "We will work through an indepth case study on constructing a protein–ligand binding interaction model. For\n",
        "experimentation,we will introduce the PDBBind dataset, which contains a collection\n",
        "of experimentally determined protein–ligand structures. We will demonstrate how to\n",
        "featurize this dataset with DeepChem. We will then build some models, both deep\n",
        "and simpler, on these featurized datasets and study their performance.\n",
        "\n",
        "2.\n",
        "it’s\n",
        "extremely important to realize that in reality, any given drug is\n",
        "going to interact with many different subsystems in the body. The\n",
        "study of such multifaceted interactions is broadly called polyphar‐\n",
        "macology.\n",
        "At present, computational methods for dealing with polypharma‐\n",
        "cology are still relatively undeveloped, so the gold standard for test‐\n",
        "ing for polypharmacological effects remains animal and human\n",
        "experimentation. As computational techniques mature, this state of\n",
        "affairs may shift over the next few years.\n",
        "\n",
        "3.\n",
        " predicting 3D protein structures computationally.\n",
        "\n",
        "1) homology modeling.\n",
        "proteins-homologs that recently diverged from each other probably have similar structures. first, look for a\n",
        "homolog whose structure is already known, then try to adjust it based on differences\n",
        "between the sequences of the two proteins.\n",
        "the thing is, you need to know the structure of a homologous protein.\n",
        "\n",
        "2) physical modeling.\n",
        "Using knowledge of the laws of phys‐\n",
        "ics, you try to explore many different conformations the protein might take on and\n",
        "predict which one will be most stable.\n",
        "\n",
        " requires enormous amounts of\n",
        "computing time.  Even today it is\n",
        "only practical for small, fast-folding proteins.\n",
        "it requires approximations to speed up the calculation, and those reduce the accuracy of the\n",
        "result. Physical modeling will often predict the right structure, but not always.\n"
      ],
      "metadata": {
        "id": "z0geFa165EUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Methods for determining the structures of proteins:\n",
        "1. X-ray crystallography\n",
        "Limitations: slow, expensive, static snapshot while many proteins are flexible and may take on a range of structures, packing the protein into a crys‐\n",
        "tal may alter its structure, so the result might be different from its structure in a living cell.\n",
        "2. nuclear magnetic resonance (NMR for short)\n",
        "Advantages: can be used for those that do not form a crystal, produces an ensemble of structures representing the range of shapes\n",
        "the protein can take on in solution.\n",
        "Limitations: requires a highly concentrated solution, so it is mostly limited to small,\n",
        "highly soluble proteins.\n",
        "3. cryo-electron\n",
        "microscopy (cryo-EM for short).\n",
        "Unlike crystallography and NMR, it\n",
        "works for large proteins that do not crystallize.\n",
        "\n",
        "Protein Data Bank\n",
        "https://www.rcsb.org/"
      ],
      "metadata": {
        "id": "Vbg1fDXE5wGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Protein theory:\n",
        "\n",
        "i. The start of the amino acid chain is typically referred to as the. N-terminus, while the\n",
        "end of the chain is called the C-terminus.\n",
        "\n",
        "ii. Peptides. Small chains of amino acids are commonly\n",
        "called peptides, while longer chains are called proteins. Peptides are too small to have\n",
        "complex 3D structures, but the structures of proteins can be very complicated.\n",
        "\n",
        "iii. It’s worth noting that while most proteins take a rigid shape, there are also intrinsi‐\n",
        "cally disordered proteins which have regions that refuse to take rigid shapes. They are challenging to handle computationally.\n",
        "\n",
        "iv. signaling transduction in cells often passes messages via the mechanism of a protein binding to another molecule. so the molecule is delivered via the bloodstream, binds the protein in the cell membrane and protein initiates the response of the cell. This is how hormones work. We want to figure out how to impact the behaviour of the cell ourselves.\n",
        " Other times, the molecule binding to the protein is foreign: possibly a drug we’ve created to manipulate the protein, possibly a toxin that interferes with its function.\n",
        "\n",
        " Why determining how binding happens is hard:\n",
        " A tiny change in the positions of just a few atoms can determine\n",
        "whether or not a molecule binds to a protein. Furthermore, many proteins are flexible and constantly moving. A protein might be able to bind a molecule when it’s in certain conformations, but not when it’s in others."
      ],
      "metadata": {
        "id": "kCUYu183BPeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biophysical Featurizations\n",
        "\n",
        "i)\n",
        "\n",
        "grid featurization\n",
        "\n",
        "explicitly searches a 3D structure (represented in the format about which you can read below)\n",
        "for the presence of critical physical interactions such as hydrogen bonds and salt\n",
        "bridges (more on these later), which are known to play an important role in deter‐\n",
        "mining protein structure. So the human explicitly tells the algorithm which interactions to look for. The advantage of this technique is that we can rely upon a\n",
        "wealth of known facts about protein physics. The weakness, of course, is that we are\n",
        "bound by known physics and lessen the chance that our algorithms will be able to\n",
        "detect new physics.\n",
        "\n",
        "ii)\n",
        "\n",
        "atomic featurization\n",
        "\n",
        " which simply pro‐\n",
        "vides a processed representation of the 3D positions and identities of all atoms in the\n",
        "system (what this representation is read below). This makes the challenge for the learning algorithm considerably harder,\n",
        "since it must learn to identify critical physical interactions, but it also makes it feasi‐\n",
        "ble for learning algorithms to detect new patterns of interesting behavior.\n",
        "\n",
        "iii) Fingerprints\n",
        "\n",
        " These fin‐\n",
        "gerprints count the number of fragments of a given type in the molecule, then use a\n",
        "hash function to fit these fragment counts into a fixed-length vector.\n",
        "\n",
        " insufficient to compute the geometry of the system, the knowl‐\n",
        "edge of present fragments can nevertheless be useful for machine learning systems as it can be\n",
        "strongly indicative of some molecular events.\n",
        "\n",
        "PDB Files and Their Pitfalls\n",
        "\n",
        "Such files are sim‐\n",
        "ply text files that contain descriptions of the atoms in the structure\n",
        "and their positions in coordinate space relative to one another.\n",
        "Often, an experiment will fail to have ade‐\n",
        "quate resolution to completely specify a portion of the protein’s\n",
        "structure. Such regions are left unspecified in the PDB file, so it’s\n",
        "common to find that many atoms or even entire substructures of\n",
        "the protein are missing from the core structure.\n",
        " DeepChem will often attempt to do the “right”\n",
        "thing and algorithmically fill in such missing regions. It’s important\n",
        "to note that this cleanup is only approximate, and there’s still no\n",
        "entirely satisfactory replacement to having an expert human peer at\n",
        "the protein structure ."
      ],
      "metadata": {
        "id": "B4OP3Zy7Kuax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some details of  RdkitGridFeaturizer implementation:\n",
        "\n",
        "The data is represented in the format:\n",
        "\n",
        "\n",
        "Most operations trans‐\n",
        "form a molecule with N atoms into a NumPy array of shape (N, 3) and then perform\n",
        "a variety of extra computations starting from these arrays.\n",
        "The (N, 3) position\n",
        "array doesn’t distinguish atom types, so you also need to provide another array that\n",
        "lists the atomic number of each atom. As a second implementation-driven note, com‐\n",
        "puting pairwise distances between two position arrays of shape (N, 3) can be very\n",
        "computationally expensive. It’s useful to create “neighbor lists” in a preprocessing\n",
        "step, where the neighbor list maintains a list of neighboring atoms close to any given\n",
        "atom.\n",
        "DeepChem provides a dc.feat.ComplexNeighborListFragmentAtomicCoordinates\n",
        "featurizer that handles much of this for you. We will not discuss it further in this\n",
        "chapter, but it’s good to know that it exists as another option.\n",
        "\n",
        "Data in this same format can be passed to ML algorithm so that it could learn\n",
        "for itself what features were important.\n",
        "\n",
        "RdkitGridFeaturizer searches for:\n",
        "\n",
        "a) Hydrogen bonds\n",
        "\n",
        "The RdkitGridFeaturizer attempts to count the hydrogen bonds present in a struc‐\n",
        "ture by checking for pairs of protein/ligand atoms of the right types that are suitably\n",
        "close to one another. This requires applying a cutoff to the distance, which is some‐\n",
        "what arbitrary. In reality there is not a sharp division between atoms being bonded\n",
        "and not bonded. This may lead to some misidentified interactions, but empirically, a\n",
        "simple cutoff tends to work reasonably well.\n",
        "\n",
        "b) Salt bridges\n",
        "\n",
        "in proteins are bonds between oppositely charged residues that are sufficiently close to each other to experience electrostatic attraction. They contribute to protein structure and to the specificity of interaction of proteins with other biomolecules, but in doing so they need not necessarily increase a protein's free energy of unfolding.\n",
        "The salt bridge most often arises from the anionic carboxylate (RCOO−) of either aspartic acid or glutamic acid and the cationic ammonium (RNH3+) from lysine or the guanidinium (RNHC(NH2)2+) of arginine.\n",
        "\n",
        "The grid featurizer attempts to detect salt bridges by explicitly checking for pairs of\n",
        "amino acids (such as glutamic acid and lysine) that are known to form such interac‐\n",
        "tions, and that are in close physical proximity in the 3D structure of the protein\n",
        "\n",
        "c)pi-stacking interactions\n",
        "\n",
        "occur when two aromatic rings “stack” on\n",
        "top of each other.  Importantly, pi-stacking interactions can be found in ligandprotein interactions, since aromatic rings are often found in small molecules. The\n",
        "grid featurizer counts these interactions by detecting the presence of aromatic rings\n",
        "and checking for the distances between their centroids and the angles between their\n",
        "two planes.\n",
        "\n",
        "Keep this\n",
        "in mind, and note that when someone says a salt bridge exists, what\n",
        "they really mean is that in some statistically average sense, a salt\n",
        "bridge is likely present more often than not at a particular location."
      ],
      "metadata": {
        "id": "UBV_HdknK0jd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model to predict the binding affinity for a complex given the protein–ligand structure.\n",
        "\n",
        "Data and goal:\n",
        "\n",
        "The PDBBind dataset contains a large number of biomolecular crystal structures and\n",
        "their binding affinities.\n",
        "The large majority of these are protein–ligand complexes, but the dataset also\n",
        "contains protein–protein, protein–nucleic acid, and nucleic acid–ligand complexes.\n",
        "For our purposes, we will focus on the protein–ligand subset. The full dataset con‐\n",
        "tains close to 15,000 such complexes, with the “refined” and “core” sets containing\n",
        "smaller but cleaner subsets of complexes. Each complex is annotated with an experi‐\n",
        "mental measurement of the binding affinity for the complex. The learning challenge\n",
        "for the PDBBind dataset is to predict the binding affinity for a complex given the pro‐\n",
        "tein–ligand structure."
      ],
      "metadata": {
        "id": "SMGjCiAybxNa"
      }
    }
  ]
}